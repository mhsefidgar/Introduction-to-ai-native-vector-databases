{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b82336",
   "metadata": {},
   "source": [
    "# Jeopardy Vector Search Lab\n",
    "This notebook demonstrates how to build a semantic search application using **Weaviate**, an open-source vector database. Unlike traditional databases that search for exact keywords, vector databases search for *meaning*.\n",
    "\n",
    "### 1. Load the data\n",
    "We start by fetching a small dataset of Jeopardy questions in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44467843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Download the data\n",
    "resp = requests.get('https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\n",
    "data = json.loads(resp.text)\n",
    "\n",
    "# Parse the JSON and preview the first item\n",
    "print(f\"Loaded {len(data)} items.\")\n",
    "print(\"Preview of first item:\")\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37e708",
   "metadata": {},
   "source": [
    "### 2. Initializing Weaviate (The Vector DB)\n",
    "\n",
    "**What is a Vector Database?**\n",
    "A vector database stores data as numerical representations called **embeddings**. These embeddings capture the semantic relationship between data points. In our case, the database will use an AI model (OpenAI) to convert Jeopardy questions into vectors. \n",
    "\n",
    "\n",
    "\n",
    "When you query the database, Weaviate converts your query into a vector and finds the nearest data points in high-dimensional space.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate import EmbeddedOptions\n",
    "import os\n",
    "\n",
    "# Start up an instance of Weaviate using Embedded mode\n",
    "# Note: You will need an OpenAI API key to vectorize the text\n",
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(),\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": os.environ.get(\"OPENAI_API_KEY\") # Ensure this is set in your environment\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153abe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that weaviate is up and running\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the schema if it already exists to ensure a fresh start\n",
    "if client.schema.exists(\"Question\"):\n",
    "    client.schema.delete_class(\"Question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "schema_doc",
   "metadata": {},
   "source": [
    "### 3. Defining the Schema\n",
    "We define a class called `Question`. We specify `text2vec-openai` as the vectorizer, which tells Weaviate to automatically create vectors for any text we upload using OpenAI's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema that will house our data\n",
    "class_obj = {\n",
    "    \"class\": \"Question\",\n",
    "    \"vectorizer\": \"text2vec-openai\",  \n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)\n",
    "print(\"Schema created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_doc",
   "metadata": {},
   "source": [
    "### 4. Batch Import\n",
    "Batching is more efficient than uploading items one by one. During this process, Weaviate sends the text to OpenAI, receives the vector, and stores both the original text and the vector in its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea81ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.batch.configure(batch_size=100) as batch:\n",
    "    for i, d in enumerate(data):\n",
    "        print(f\"Importing question: {i+1}\")\n",
    "            \n",
    "        properties = {\n",
    "            \"answer\": d[\"Answer\"],\n",
    "            \"question\": d[\"Question\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "        }\n",
    "        \n",
    "        client.batch.add_data_object(\n",
    "            data_object=properties,\n",
    "            class_name=\"Question\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many objects we've loaded\n",
    "count = client.query.aggregate(\"Question\").with_meta_count().do()\n",
    "json_print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query_doc",
   "metadata": {},
   "source": [
    "### 5. Preview the Data\n",
    "We can now query the database to verify the content. In a real application, you would use `.with_near_text()` here to perform semantic searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and show any 3 questions and answers\n",
    "result = client.query.get(\"Question\", [\"question\", \"answer\", \"category\"])\\\n",
    "    .with_limit(3).do()\n",
    "\n",
    "json_print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
